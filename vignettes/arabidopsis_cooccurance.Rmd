---
title: "Arabidopsis Cooccurance"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{Arabidopsis Cooccurance}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

Load packages
```{r setup, include=FALSE}
library(CoreMicro)
library(phyloseq)
library(parallelDist)
library(vegan)
library(backbone)
library(tidyverse)
library(igraph)
library(visNetwork)
```

```{r}
arab_md<-read.csv("/Users/gordoncuster/Desktop/Manuscript Submissions/In Review/Core_community/November2020/Data_for_additional_analyses/Lundberg454_MetadataF.csv")
rownames(arab_md) <- arab_md$Sample
arab_md$Sample = NULL

arab_otu<-read.csv("/Users/gordoncuster/Desktop/Manuscript Submissions/In Review/Core_community/November2020/Data_for_additional_analyses/lundfull.csv")
rownames(arab_otu)<-arab_otu$Sample  
arab_otu$Sample  = NULL

arab_tabb<-otu_table(arab_otu, taxa_are_rows = T)
arab_sample_data<-sample_data(arab_md)

arab_ps<-phyloseq(arab_tabb, arab_sample_data)
#subset to those samples that our core analysis was conducted with
arab_working_set<-subset_samples(physeq = arab_ps, Soil.Type=="M21" & Treatment == "R")
arab_m21_r<- prune_taxa(taxa_sums(arab_working_set) >=1, arab_working_set)
```

Assign core membership

```{r}
arab_core_df <- core_methods(arabidopsis) %>% data.frame()
table(arab_core_df$name, arab_core_df$value)

# Create table all taxa that are never assigned.
wide_arab <- pivot_wider(arab_core_df)
#table(rowSums(wide_human[,5:8]))
wide_arab$num_methods <- (rowSums(wide_arab[,5:8]))
#tables number assigned by each method to add in paper. 
#table(wide_human$`Proportion of Sequence Reads`)
#table(wide_human$`Proportion of Sequence Reads and Replicates`)
#table(wide_human$`Hard Cut Off`)
#table(wide_human$`Proportion of Sequence Replicates`)

#pull out those common taxa found by all
core_4 <-(wide_arab[wide_arab$num_methods==4,])$X
#pull out those taxa included by each method
prop_seq_reads_core <- (wide_arab[wide_arab$`Proportion of Sequence Reads`==1,])$X
prop_seq_readsnrep_core <-(wide_arab[wide_arab$`Proportion of Sequence Reads and Replicates`==1,])$X
HC_core <- (wide_arab[wide_arab$`Hard Cut Off`==1,])$X
prop_rep_core <- (wide_arab[wide_arab$`Proportion of Sequence Replicates`==1,])$X

assigned_by_any<-unique(c(prop_seq_reads_core, prop_seq_readsnrep_core, HC_core, prop_rep_core))
```

# Adonis

## Prep Data

```{r}
md_a<-data.frame(sample_data(arab_m21_r))
otu_a<-data.frame(otu_table(arab_m21_r))
otu_a_t<-data.frame(t(otu_a))
otu_a_t<-data.frame(otu_a_t)
```

## Create Binary and Bray Functions 

```{r}
adonis_binary <- function(data) {
  dist <- parallelDist(data.matrix(data), method = "binary")
  adonis(dist ~ Developmental + Arabidopsis , data=md_a)
}

adonis_bray <- function(data) {
  dist <- parallelDist(data.matrix(data), method = "bray")
  adonis(dist ~ Developmental + Arabidopsis, data=md_a)
}
```

### full human microbiome stool dataset

```{r}
adonis_binary(otu_a_t)
adonis_bray(otu_a_t)
```

### Core 4

Core 4
```{r}
human_core_4 <- otu_a_t[,names(otu_a_t) %in% core_4]

adonis_binary(human_core_4)
adonis_bray(human_core_4)
```

Prop Seq reads
```{r}
human_prop_seq_reads_core <- otu_a_t[,names(otu_a_t) %in% prop_seq_reads_core]

adonis_binary(human_prop_seq_reads_core)
adonis_bray(human_prop_seq_reads_core)
```

Prop Read N Rep
```{r}
human_prop_rnr_core<- otu_a_t[,names(otu_a_t) %in% prop_seq_readsnrep_core]

adonis_binary(human_prop_seq_reads_core)
adonis_bray(human_prop_seq_reads_core)
```

HC
```{r}
human_HC_core <- otu_a_t[,names(otu_a_t) %in% HC_core]

adonis_binary(human_HC_core)
adonis_bray(human_HC_core)
```

Prop Rep
```{r}
human_prop_rep_core <- otu_a_t[,names(otu_a_t) %in% prop_rep_core]

adonis_binary(human_prop_rep_core)
adonis_bray(human_prop_rep_core)
```

#Network analysis 
```{r}
md_a<-data.frame(sample_data(arab_m21_r))
otu_a<-data.frame(otu_table(arab_m21_r))

#Network of full dataset
#http://pablobarbera.com/big-data-upf/html/02b-networks-descriptive-analysis.html
network_test_dat<-otu_a

network_test_dat2 <- network_test_dat %>% mutate_if(is.numeric, ~1 * (. > 0))

rownames(network_test_dat2)<-rownames(network_test_dat)

network_arab<-hyperg(as.matrix(network_test_dat2))

hyperg_arab_network_sig <- backbone.extract(network_arab, alpha = .0001, class = "igraph", fwer = "bonferroni", narrative = TRUE)

#Gives same output as below.
#sorted_degree_arab_nodes<-sort(degree(hyperg_arab_network_sig), decreasing = T)

node_extract_full_arab<-hyperg_arab_network_sig[[]]

nodes_with_sig_full_arab<-node_extract_full_arab[lapply(node_extract_full_arab,length)>0]

full_arab_node_w_num_edges<-sort(lengths(nodes_with_sig_full_arab), decreasing = T) 
str(full_arab_node_w_num_edges)
arab_node_list<-names(full_arab_node_w_num_edges)

```
```{r}

# calculate average number of edges for all taxa
all_edges<-lapply(node_extract_full_arab,length)
summary(unlist(all_edges))

#calculate average number of edges for core taxa
all_edges_vec<-data.frame(unlist(all_edges))
core_edges<- all_edges_vec[rownames(all_edges_vec) %in% assigned_by_any,]
table(core_edges)
summary(core_edges)

#calculate average number of edges for non-core taxa
all_edges_vec<-data.frame(unlist(all_edges))
noncore_edges<- all_edges_vec[!rownames(all_edges_vec) %in% assigned_by_any,]
summary(noncore_edges)
```



Comparison of human nodes with taxa identified by core methods
Intersetion of core assignment methods with global signficance network nodes

```{r}
uncommon_core_intersect <- function(data) {
  full_arab_node_w_num_edges[!names(full_arab_node_w_num_edges) %in% intersect(data, arab_node_list)]
}

common_core_intersect <- function(data) {
  full_arab_node_w_num_edges[names(full_arab_node_w_num_edges) %in% intersect(data, arab_node_list)]
}
```

```{r}
#Core_4
uncommon_core_intersect(core_4)
common_core_intersect(core_4)

#Prop_Reads
uncommon_core_intersect(prop_seq_reads_core)
common_core_intersect(prop_seq_reads_core)

#Prop_Reps
uncommon_core_intersect(prop_rep_core)
common_core_intersect(prop_rep_core)

#PropRnR
uncommon_core_intersect(prop_seq_readsnrep_core)
common_core_intersect(prop_seq_readsnrep_core)

#HCs
uncommon_core_intersect(HC_core)
common_core_intersect(HC_core)
```

Barplot of inclusion by group status
```{r}
taxa_in_core_by_any_method <- unique(
  c(
    as.character(prop_seq_reads_core), 
    as.character(prop_rep_core), 
    as.character(prop_seq_readsnrep_core), 
    as.character(HC_core)
    )
  )

#taxa in network with edge > 1
full_arab_node_w_num_edges

#could be accomplished with just the intersect command too. Its currenlty the long way.
shared_core_network_taxa <- common_core_intersect(taxa_in_core_by_any_method)

taxa_only_in_core <- taxa_in_core_by_any_method[!taxa_in_core_by_any_method %in% names(shared_core_network_taxa)]

taxa_only_in_network <- uncommon_core_intersect(taxa_in_core_by_any_method)

# summary of degree of each node. 
# no info is available for taxa only in the core 
# becasue they werent included in the network. 
summary(shared_core_network_taxa)
summary(taxa_only_in_network)

# I think this would be better as a venn diagram actaully. 
counts<-c(
  length(shared_core_network_taxa), 
  length(taxa_only_in_core), 
  length(taxa_only_in_network)
 )

barplot(counts)
```

```{r, warning=FALSE, message=FALSE}
list(
  core = taxa_in_core_by_any_method,
  network = arab_node_list
) %>%
  ggVennDiagram::ggVennDiagram(label = "both", category.names = c("", ""), size = 2, color = "black") +
  annotate("text", x = -1.3, y = 0.8, label = "CORE", fontface =2) +
  annotate("text", x = 5.3, y = 0.8, label = "NETWORK", fontface =2) +
  scale_fill_gradient(high = "grey", low = "white") +
  guides(fill = FALSE) + ggtitle("Overalap of Important Taxa \n Arabidopsis") + theme(plot.title = element_text(hjust = 0.5))
```


